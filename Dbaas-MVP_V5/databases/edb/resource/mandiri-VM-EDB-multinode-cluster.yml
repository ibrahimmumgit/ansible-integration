---
- name: Create a VM from a template
  hosts: localhost
  vars_files:
    - "./vars/edb_provision.yml"
  vars:
  - vm_name: "EDB_Deployed"
  - datacenter_name: "DBaaS_Datacenter"
  - folder_name : "/vm/"
  - cpu: 4
  - memory: 8192
  - vm_network: "VM Network"
  - datastore: "DBaaSMgmt_DS2"
  - vmware_cluster_name: "DBaaS_Cluster"
  - ssh_user: "root"
  - ssh_pass: "P@ssw0rd123"
  - db_size: "30"
  - disk_number: 1
  - tenant_name: hpedbaas
  - os_version: "RHEL 7.8"
  - dict_list: { cpu: "{{ cpu }}", memory: "{{ memory}}", db_size: "{{ db_size}}", disk_number: "{{ disk_number }}" }
  - template_dict: { "RHEL 7.8": "RHEL-RAC-MK", "RHEL 8": "RHEL-OS-8" }
  - rollback: true
  - uuids_val: []
  - nodes: 1 
  tasks:
  - name: Validate input parameters.
    include_role:
      name: hpe-validate-params
    vars:
      type: int      

  - name: Morpheus set fact
    set_fact:
      uuid: '{{ morpheus[''server''][''uniqueId'']}}'
      vmname: '{{ morpheus[''server''][''name'']}}'
      db_machine_ip: '{{ morpheus[''internalIp'']}}'
      compatible_mode: "{{ morpheus['customOptions']['compatiblemode'] }}"
      db_name: "{{ morpheus['customOptions']['DBName'] }}"
      dynatune_profile: "{{ morpheus['customOptions']['workloadprofile'] }}"
      edb_version: "{{ morpheus['customOptions']['edbversion'] }}"
      edb_sub_version: "{{ morpheus['customOptions']['edb_subversion'] }}"
      input_password: "{{ morpheus['customOptions']['db_password'] }}"
      db_size: "{{ morpheus['customOptions']['pgdata_size'] }}"
      disk_number: "{{ morpheus['customOptions']['number_of_disks'] }}"

  - meta: end_play

  - name: Get the hostname sequence
    tags: never
    set_fact:
      vm_list: "{{vm_list|default([])+[{'vmname': tenant_name+'-'+lookup('password','/dev/null chars=digits length=6'), 'hostname': tenant_name+'-node'+item+'.'+domain_name}]}}"
    with_sequence: start=1 end="{{nodes|int}}"
   # It generates random vm names

  - name: Get the hostname sequence
    set_fact:
      vm_list: "{{vm_list|default([])+[{'vmname': vmname, 'hostname': vmname }]}}"
      
  - name: SNOW_fetch_facts
    set_fact:
      compatible_mode: "{{compatible_mode}}"
      dynatune_profile: "{{dynatune_profile}}"
      replication_mode: "{{replication_mode}}"

  - name: VM template
    tags: never
    set_fact:
      template_name: "{{item.value}}"
    when: item.key == os_version
    with_dict: "{{ template_dict}}"

  - block:
    - name: Clone the template
      tags: never
      vmware_guest:
        hostname: "{{ vcenter_ip }}"
        username: "{{ vcenter_username }}"
        password: "{{ vcenter_password }}"
        validate_certs: False
        name: "{{ item.vmname}}"
        template: "{{ template_name }}"
        datacenter: "{{ datacenter_name }}"
        cluster: "{{ vmware_cluster_name }}"
        folder: "{{ folder_name }}"
        state: poweredon
        hardware:
          hotadd_cpu: True
          hotadd_memory: True
          hotremove_cpu: True
#          hotremove_memory: True
          num_cpus: "{{ cpu | int }}"
          memory_mb: "{{ memory | int }}"
        networks:
        - name: "{{ public_net }}"
        datastore: "{{ datastore }}"
        wait_for_ip_address: yes
      register: vm_details
      with_items: "{{vm_list}}"

    - name: SNOW_fetch_facts
      set_fact:
        primary_ip: "{{ db_machine_ip }}"
#        primary_ip: "{{vm_details.results[0].instance.ipv4}}"
      #Gets the the ip of 1st VM and sets it as primary ip  

    - name: Getting the standby ips
      set_fact:
        standby: "{{vm_details.results[1].instance.ipv4}}"
      when: nodes | int ==2

    - name: Getting the standby ips
      set_fact:
        standby: "{{vm_details.results[1].instance.ipv4}},{{vm_details.results[item].instance.ipv4}}"
      loop: "{{ range(1,nodes|int)|list }}"
      when: nodes | int >2

    - name: SNOW_fetch_facts
      set_fact:
        standby_ips: "{{standby}}"
      when: nodes | int >1

    - debug:
        var: vm_details.results
      tags: never

    - debug:
        var: vm_details.results.item.invocation.hostname
      with_items: "{{vm_details.results}}"
      tags: never

    - debug:
        var: item.invocation.name
      with_items: "{{vm_details.results}}"
      tags: never

    - name: Create nodes list
      tags: never
      set_fact:
        rac_hosts: "{{rac_hosts|default([]) + [{'node_hostname': item.item.hostname,'vmname': item.item.vmname, 'node_ip':item.instance.ipv4, 'uuid':item.instance.hw_product_uuid}]}}"
        rac_vms: "{{rac_vms|default([]) + [item.item.vmname]}}"
      with_items: "{{vm_details.results}}"

    - name: Create nodes list
      set_fact:
        rac_hosts: "{{rac_hosts|default([]) + [{'node_hostname': vmname,'vmname': vmname, 'node_ip': db_machine_ip , 'uuid': uuid}]}}"
        rac_vms: "{{rac_vms|default([]) + [vmname]}}"

    - name: SNOW_fetch_facts
      set_fact:
        edb_nodes: "{{rac_hosts}}"
        
    - name: Getting rac hosts details
      set_fact:
        rac_nodes: "{{rac_hosts}}"        

    - set_fact:
        rac_node_uuids: "{{rac_node_uuids|default([]) + [item.uuid]}}"
      with_items: "{{rac_nodes}}"

    - name: Reference vm
      set_fact:
        reference_vm_uuid: "{{rac_nodes[0]['uuid']}}"

    - name: SNOW_fetch_facts
      set_fact:
        uuid: "{{rac_nodes[0]['uuid']}}"

    - name: SNOW_fetch_facts
      set_fact:
        vmname: "{{rac_nodes[0]['vmname']}}"

    - name: Removing entry from known_hosts if any
      known_hosts:
       name: "{{ item.node_ip }}"
       #path: /root/.ssh/known_hosts
       path: /opt/morpheus/.local/.ssh/known_hosts
       state: absent
      with_items: "{{rac_nodes}}"
      ignore_errors: yes

    - name: Adding db vm to inventory
      add_host:
        hostname: "{{  item.node_ip }}"
        vmname: "{{item.vmname}}"
        uuid: "{{ item.uuid }}"
        ansible_ssh_user: "{{ ansible_ssh_user }}"
        ansible_ssh_pass: "{{ ansible_ssh_pass }}"
        groups: [ 'vmedbgroup' ]
      with_items: "{{rac_nodes}}"
      ignore_errors: yes

    - name: set uuids_val for adding disk
      set_fact:
        uuids_val: "{{ uuids_val + [item.uuid] }}"
      with_items: "{{rac_nodes}}"
        
    - name: SNOW_fetch_facts
      set_fact:
        replication_type: asynchronous
      when: replication_mode=="performance"
      
    - name: SNOW_fetch_facts
      set_fact:
        replication_type: synchronous
      when: replication_mode=="protection"          

    - name: Adding db vm to inventory file
      add_host:
        hostname: "{{vm_list[0].vmname}}"
        ansible_host: "{{ primary_ip }}"
        private_ip: "{{ primary_ip }}"
        barman: false
        barman_server_private_ip: "{{barman_ip}}"
        barman_backup_method: postgres
        pem_agent: false
        pem_server_private_ip: "{{pem_ip}}"
        groups: [ 'primary' ]
      # It adds the inventory of primary node  

    - name: Adding db vm to inventory file
      add_host:
        hostname: "{{vm_list[item].vmname}}"
        ansible_host: "{{vm_details.results[item].instance.ipv4}}"
        private_ip: "{{vm_details.results[item].instance.ipv4}}"
        upstream_node_private_ip: "{{ primary_ip }}"
        replication_type: "{{replication_type}}"
        barman: false
        barman_server_private_ip: "{{barman_ip}}"
        barman_backup_method: postgres
        pem_agent: false
        pem_server_private_ip: "{{pem_ip}}"
        groups: [ 'standby' ]
      loop: "{{ range(1,nodes|int)|list }}"  
      when: nodes | int >1 and ( replication_mode=="performance" or replication_mode=="protection")
      # It adds the inventory of standby node
      
    - name: Adding db vm to inventory file
      add_host:
        hostname: "{{vm_list[1].vmname}}"
        ansible_host: "{{vm_details.results[1].instance.ipv4}}"
        private_ip: "{{vm_details.results[1].instance.ipv4}}"
        upstream_node_private_ip: "{{ primary_ip }}"
        replication_type: synchronous
        barman: false
        barman_server_private_ip: "{{barman_ip}}"
        barman_backup_method: postgres
        pem_agent: false
        pem_server_private_ip: "{{pem_ip}}"
        groups: [ 'standby' ]
      when: nodes | int >1 and replication_mode=="availability" 
      # It adds the inventory of standby node   
      
    - name: Adding db vm to inventory file
      add_host:
        hostname: "{{vm_list[item].vmname}}"
        ansible_host: "{{vm_details.results[item].instance.ipv4}}"
        private_ip: "{{vm_details.results[item].instance.ipv4}}"
        upstream_node_private_ip: "{{ primary_ip }}"
        replication_type: asynchronous
        barman: false
        barman_server_private_ip: "{{barman_ip}}"
        barman_backup_method: postgres
        pem_agent: false
        pem_server_private_ip: "{{pem_ip}}"
        groups: [ 'standby' ]
      loop: "{{ range(2,nodes|int)|list }}"  
      when: nodes | int >2 and replication_mode=="availability" 
      # It adds the inventory of standby node       

    - name: Adding db vm to inventory file
      add_host:
        hostname: "{{vm_list[item].vmname}}"
        ansible_host: "{{vm_details.results[item].instance.ipv4}}"
        private_ip: "{{vm_details.results[item].instance.ipv4}}"
        primary_private_ip: "{{ primary_ip }}"
        groups: [ 'pgpool2' ]
      loop: "{{ range(0,nodes|int)|list }}"        
      when: pgpool_enable==true and nodes | int >1
      # It adds the inventory of pgpool

    - name: Adding backup IP to inventory file
      add_host:
        hostname: "backup_server"
        ansible_host: "{{barman_ip}}"
        private_ip: "{{barman_ip}}"
        groups: [ 'barmanserver' ]
      when: barman==true
      # It adds the inventory of barman server

    - name: Adding backup IP to inventory file
      add_host:
        hostname: "pemserver_1"
        ansible_host: "{{pem_ip}}"
        private_ip: "{{pem_ip}}"
        groups: [ 'pemserver' ]
      when: pem_agent==true
      # It adds the inventory of pem server

    - name: getting rac hosts details
      set_fact:
        rac_nodes: "{{rac_hosts}}"

    - set_fact:
        rac_node_uuids: "{{rac_node_uuids|default([]) + [item.uuid]}}"
      with_items: "{{rac_nodes}}"

    - debug:
        var: rac_nodes
        
    - name: VM uuids List
      set_fact:
        vm_uuids: "{{vm_uuids|default([]) + [rac_nodes[item]['uuid']]}}"
      loop: "{{ range(0,nodes|int)|list }}"  
      
    - set_fact:
        uuids: "{{vm_uuids}}"      
      
    rescue:
    - name: Delete VM
      include_role:
        name: hpe-deprovision-db
      when: uuid is defined and rollback
      vars:
        uuids: "{{uuids}}"
        deprovision: "vm"
    - name: SNOW_fetch_facts
      fail:
        msg: "Failed while cloning VM"

- name: Gather Disk facts and Add New Disk
  hosts: localhost
  vars_files:
    - "./vars/edb_provision.yml"
  vars:
    rollback: true
  tasks:
  - block:
    - name: include task for adding
      include_tasks: edb_extend_disk_multiple.yml
      with_items: "{{ uuids_val }}"
    rescue:
    - name: Delete VM
      include_role:
        name: hpe-deprovision-db
      when: uuid is defined and rollback
      vars:
        uuids: "{{uuids}}"   
        deprovision: "vm"
    - name: SNOW_fetch_facts
      fail:
        msg: "Failed to provision disks"

- name: get disk names from host
  hosts: vmedbgroup
  vars_files:
    - "./vars/edb_provision.yml"
  vars:
    rollback: true
    ssh_user: enterprisedb
  tasks:
  - set_fact:
      compatible_mode: "{{ hostvars['localhost']['compatiblemode'] }}"
      db_name: "{{ hostvars['localhost']['DBName'] }}"
      dynatune_profile: "{{ hostvars['localhost']['workloadprofile'] }}"
      edb_version: "{{ hostvars['localhost']['edbversion'] }}"
      edb_sub_version: "{{ hostvars['localhost']['edb_subversion'] }}"
      input_password: "{{ hostvars['localhost']['db_password'] }}"
      db_size: "{{ hostvars['localhost']['pgdata_size'] }}"
      disk_number: "{{ hostvars['localhost']['number_of_disks'] }}"
  - block:
    - include_role:
        name: hpe-enable-passwordless-login
    - set_fact:
        new_unit_numbers: "{{ hostvars['localhost']['new_unit_numbers'] }}"
    - name: shell
      shell: ls -d /sys/block/sd*/device/scsi_device/* |awk -F '[:/]' '{print "/dev/"$4,$9}' | grep "{{ item }}" | cut -f1 -d " "
      register: disk_names
      with_items:
      - "{{ new_unit_numbers }}"
    - set_fact:
        db_disks: "{{db_disks |default([]) + [item.stdout] }}"
        data_disks: "{{data_disks|default([]) + [{ 'device': item.stdout, 'pvname': item.stdout }]}}"
      when: item.stdout
      with_items:
      - "{{disk_names.results }}"

    rescue:
    - name: Delete VM
      include_role:
        name: hpe-deprovision-db
      when: uuid is defined and rollback
      vars:
        uuids: ["{{hostvars['localhost']['uuids']}}"]   
        deprovision: "vm"
    - name: SNOW_fetch_facts
      fail:
        msg: "Error occurred while gathering disk facts"
  
- name: Configure fs,vgs and lvs
  hosts: vmedbgroup
  vars_files:
    - "./vars/edb_provision.yml"
  vars:
    rollback: true
    configure_host_disks: true
  tasks:
  - block:
    - set_fact:
        mnt_pt: "/pg/edbvol1"
      when: pg_type == 'EPAS'
      
    - set_fact:
        mnt_pt: "/pg/pgvol1"
      when: pg_type == 'PG'
      
    - include_role:
        name: hpe-edb-partition
    rescue:
    - name: Delete VM
      include_role:
        name: hpe-deprovision-db
      when: rollback
      vars:
        uuids: ["{{hostvars['localhost']['uuids']}}"] 
        deprovision: "vm"
    - name: SNOW_fetch_facts
      fail:
        msg: "Failed to add database disk"

- name: Extend vgs and lvs
  hosts: vmedbgroup
  vars_files:
    - "./vars/edb_provision.yml"
  roles:
  - role: hpe-oradb-vm-add-storage

- name: Get New DBSize
  hosts: vmedbgroup
  vars_files:
    - "./vars/edb_provision.yml"
  tasks:
  - name: run df command 
    shell: df -h | grep "{{ vg_name }}" | tail -1 | awk '{print $2}'
    register: total_lvm_size_gb
    
  - name: SNOW_fetch_facts
    set_fact:
      extended_disk_size: "{{ total_lvm_size_gb.stdout }}"

#- name: Update DNS, Hostname
#  hosts: vmedbgroup
#  become: yes
#  vars:
#    rollback: true
#    oracle_sid: "{{ database_name }}"
#  tasks:
#  - block:
#    - include_role:
#        name: hpe-configure-hostname-dns
#    rescue:
#    - name: Delete VM
#      include_role:
#        name: hpe-deprovision-db
#      when: rollback
#      vars:
#        uuids: ["{{hostvars['localhost']['uuids']}}"]       
#        deprovision: "vm"
#    - name: SNOW_fetch_facts
#      fail:
#        msg: "Error occurred while configuring database"

- name: EDB deployment
  hosts: primary,standby
  vars_files:
    - "./vars/edb_provision.yml"
  vars:
    edb_policy_file: "data/edb_policy.json"
    jsonInput: "{{ lookup('file', edb_policy_file) | from_json }}"
    policyName: "{{ backup_policy }}"
    edb_policy_full: "{{ jsonInput[policyName]['policy_full'] }}"
    frequency_full: "{{ jsonInput[policyName]['frequency_full'] }}"
    edb_retention_policy: "{{ jsonInput[policyName]['retention'] }}"
    efm_version: 4.0
    efm_parameters:
      - name: ping.server.ip
        value: "{{dns_server}}"
  gather_facts: yes
  become: yes
  any_errors_fatal: True
  max_fail_percentage: 0

  pre_tasks:
  - set_fact:
      compatible_mode: "{{ hostvars['localhost']['compatiblemode'] }}"
      db_name: "{{ hostvars['localhost']['DBName'] }}"
      dynatune_profile: "{{ hostvars['localhost']['workloadprofile'] }}"
      edb_version: "{{ hostvars['localhost']['edbversion'] }}"
      edb_sub_version: "{{ hostvars['localhost']['edb_subversion'] }}"
      input_password: "{{ hostvars['localhost']['db_password'] }}"
      db_size: "{{ hostvars['localhost']['pgdata_size'] }}"
      disk_number: "{{ hostvars['localhost']['number_of_disks'] }}"

  - name: Initialize the user defined variables
    set_fact:
      pg_version: "{{ edb_version }}"
      pg_type: "EPAS"
      pg_port: "{{ port_number }}"
      disable_logging: no         
    
  - set_fact:
      pg_superuser: enterprisedb
      pg_database: "{{compatible_mode}}"
      pg_efm_database: "{{compatible_mode}}"
      pg_databases:
        - name: "{{ db_name }}"
          owner: enterprisedb
          encoding: UTF-8
    when: pg_type == 'EPAS'
     
  - set_fact:
      pg_superuser: postgres
      pg_database: postgres
      pg_efm_database: postgres
      pg_databases:
        - name: "{{ db_name }}"
          owner: postgres
          encoding: UTF-8
      pg_service: 'postgresql-{{ edb_version }}-{{cluster_name}}-{{port_number}}'    
    when: pg_type == 'PG'  
    
  - set_fact:
      pg_initdb_options: "--auth=peer --auth-host=scram-sha-256 --encoding=UTF-8 --locale=en_US.UTF-8 --data-checksums --no-redwood-compat"
      pg_database: "postgres"
      pg_efm_database: "postgres"
    when: compatible_mode=="postgres"

  - set_fact:
      pg_instance_name: "{{ cluster_name }}-{{ pg_port }}"

  - set_fact:
      pg_data: "/pg/edbvol1/edb/as{{ pg_version }}/{{ pg_instance_name }}/data"
      pg_default_data: "/pg/edbvol1/edb/as{{ pg_version }}/{{ pg_instance_name }}/data"
    when: pg_type == 'EPAS'  
    
  - set_fact: 
      pg_data: "/pg/pgvol1/pgsql/{{ pg_version }}/{{ pg_instance_name }}/data"
      pg_default_data: "/pg/pgvol1/pgsql/{{pg_version}}/{{ pg_instance_name }}/data"
    when: pg_type == 'PG'   
      
  - name: Setting up a edb, epel and rhel repo
    get_url:
     url: "{{item}}"
     dest: /etc/yum.repos.d
     mode: '0440'
     validate_certs: no  
    loop:
     - "{{edb_repo}}"
     - "{{epel_repo}}"
     - "{{rhel_repo}}"  
    become: yes 
  tasks:
  - block:     
    - include_role:
        name: install_dbserver
      when: "'install_dbserver' in lookup('edb_devops.edb_postgres.supported_roles', wantlist=True)"
    
    - include_role:
        name: init_dbserver
      when: "'init_dbserver' in lookup('edb_devops.edb_postgres.supported_roles', wantlist=True)"
      
    - include_role:
        name: manage_dbserver
      when: "'primary' in {{ group_names }}"          
    rescue:
    - name: Delete VM
      include_role:
        name: hpe-deprovision-db        
      when: rollback
      vars:
        uuids: ["{{hostvars['localhost']['uuids']}}"] 
        deprovision: "vm"
    - name: SNOW_fetch_facts
      fail:
        msg: "Error occurred while configuring EDB database"      

- name: Snow fetch facts details of primary
  hosts: primary
  vars_files:
    - "./vars/edb_provision.yml"
  tasks:
  - set_fact:
      compatible_mode: "{{ hostvars['localhost']['compatiblemode'] }}"
      db_name: "{{ hostvars['localhost']['DBName'] }}"
      dynatune_profile: "{{ hostvars['localhost']['workloadprofile'] }}"
      edb_version: "{{ hostvars['localhost']['edbversion'] }}"
      edb_sub_version: "{{ hostvars['localhost']['edb_subversion'] }}"
      input_password: "{{ hostvars['localhost']['db_password'] }}"
      db_size: "{{ hostvars['localhost']['pgdata_size'] }}"
      disk_number: "{{ hostvars['localhost']['number_of_disks'] }}"
  - block:
    - name: Get EPAS version
      shell: psql --version|awk ' {print $3}'
      register: db_version
    - debug:
       var: db_version.stdout
    - name: SNOW_fetch_facts
      set_fact:
        db_name: "{{ db_name }}"
        cluster_name: "{{pg_instance_name}}"
        listen_port: "{{ port_number }}"
        db_version: "{{ db_version.stdout }}"
        pg_data: "{{pg_data}}"
        db_size: "{{db_size*number_of_luns}}"
        nodes: "{{nodes}}"

- name: Pgpool2 vip generation
  hosts: pgpool2
  vars_files:
    - "./vars/edb_provision.yml"
  vars: 
    oracle_cluster_name: "{{pg_instance_name}}"
  tasks:
  - set_fact:
      compatible_mode: "{{ hostvars['localhost']['compatiblemode'] }}"
      db_name: "{{ hostvars['localhost']['DBName'] }}"
      dynatune_profile: "{{ hostvars['localhost']['workloadprofile'] }}"
      edb_version: "{{ hostvars['localhost']['edbversion'] }}"
      edb_sub_version: "{{ hostvars['localhost']['edb_subversion'] }}"
      input_password: "{{ hostvars['localhost']['db_password'] }}"
      db_size: "{{ hostvars['localhost']['pgdata_size'] }}"
      disk_number: "{{ hostvars['localhost']['number_of_disks'] }}"
  - block:  
    - include_role:
        name: hpe-get-ips-from-pool
      vars:
        total_ips: "1"
        oracle_cluster_name: "{{pg_instance_name}}"
      when: pgpool_enable==true and nodes | int >1
      
    - set_fact:
        pgpool_vip: "{{usable_ips[0]}}"
      when: pgpool_enable==true and nodes | int >1
      
    - debug:
        var: cluster_name 
    
    rescue:
    - name: Delete VM
      include_role:
        name: hpe-deprovision-db
      when: rollback  
      vars:
        uuids: ["{{hostvars['localhost']['uuids']}}"] 
        deprovision: "vm"        
    - name: SNOW_fetch_facts
      fail:
        msg: "Failed, Could not get vip for pgpool2."    
  
- name: Enable Barman backup deployment
  hosts: primary,barmanserver,standby,pemserver,pgpool2
  vars_files:
    - "./vars/edb_provision.yml"
  gather_facts: yes
  become: yes
  vars:
   barman: false
   pem_agent: false
   backup_method: postgres
   use_hostname: true
   edb_policy_file: "data/edb_policy.json"
   jsonInput: "{{ lookup('file', edb_policy_file) | from_json }}"
   policyName: "{{ backup_policy }}"
   edb_policy_full: "{{ jsonInput[policyName]['policy_full'] }}"
   frequency_full: "{{ jsonInput[policyName]['frequency_full'] }}"
   edb_retention_policy: "{{ jsonInput[policyName]['retention'] }}"
   efm_version: 4.0
   efm_parameters:
     - name: ping.server.ip
       value: "{{dns_server}}"
   pgpool2_load_balancing: true
   pgpool2_watchdog: true
   pgpool2_vip_dev: "{{pgpool_dev}}"
   pgpool2_port: 5433
   total_ips: "1"
   pgpool2_vip: "{{pgpool_vip}}"
  pre_tasks:
  - set_fact:
      compatible_mode: "{{ hostvars['localhost']['compatiblemode'] }}"
      db_name: "{{ hostvars['localhost']['DBName'] }}"
      dynatune_profile: "{{ hostvars['localhost']['workloadprofile'] }}"
      edb_version: "{{ hostvars['localhost']['edbversion'] }}"
      edb_sub_version: "{{ hostvars['localhost']['edb_subversion'] }}"
      input_password: "{{ hostvars['localhost']['db_password'] }}"
      db_size: "{{ hostvars['localhost']['pgdata_size'] }}"
      disk_number: "{{ hostvars['localhost']['number_of_disks'] }}"

  - name: Initialize the user defined variables
    set_fact:
      pg_version: "{{ edb_version }}"
      pg_type: "EPAS"
      pg_port: "{{ port_number }}"      
      disable_logging: false
      any_errors_fatal: True
      max_fail_percentage: 0      
    become: yes   
  
  - set_fact:
      pg_initdb_options: "--auth=peer --auth-host=scram-sha-256 --encoding=UTF-8 --locale=en_US.UTF-8 --data-checksums --no-redwood-compat"
      pg_database: "postgres"
      pg_efm_database: "postgres"
    when: compatible_mode=="postgres"

  - set_fact:
      pg_instance_name: "{{ cluster_name }}-{{ pg_port }}"
      
  - set_fact:
      pg_superuser: enterprisedb
      pg_database: "{{compatible_mode}}"
      pg_efm_database: "{{compatible_mode}}"
      pg_databases:
        - name: "{{ db_name }}"
          owner: enterprisedb
          encoding: UTF-8
    when: pg_type == 'EPAS'
     
  - set_fact:
      pg_superuser: postgres
      pg_database: postgres
      pg_efm_database: postgres
      pg_databases:
        - name: "{{ db_name }}"
          owner: postgres
          encoding: UTF-8
      pg_service: 'postgresql-{{ edb_version }}-{{cluster_name}}-{{port_number}}'    
    when: pg_type == 'PG'
   
  - set_fact:
      pg_data: "/pg/edbvol1/edb/as{{ pg_version }}/{{ pg_instance_name }}/data"
      pg_default_data: "/pg/edbvol1/edb/as{{ pg_version }}/{{ pg_instance_name }}/data"
    when: pg_type == 'EPAS'  
    
  - set_fact: 
      pg_data: "/pg/pgvol1/pgsql/{{ pg_version }}/{{ pg_instance_name }}/data"
      pg_default_data: "/pg/pgvol1/pgsql/{{pg_version}}/{{ pg_instance_name }}/data"
    when: pg_type == 'PG' 
    
    become: yes 
  tasks: 
  - block:  
    - include_role:
        name: setup_replication
      when: "'setup_replication' in lookup('edb_devops.edb_postgres.supported_roles', wantlist=True) and ({{nodes | int}} >1)"
    
    - include_role:
        name: setup_efm
      when: "'setup_efm' in lookup('edb_devops.edb_postgres.supported_roles', wantlist=True) and ({{nodes | int}} >1)"
      
    - include_role:
        name: setup_pgpool2
      when: "'setup_pgpool2' in lookup('edb_devops.edb_postgres.supported_roles', wantlist=True) and ({{nodes | int}} >1) and {{ pgpool_enable }} == true"
      
    - include_role:
        name: setup_pemagent
      when: "'setup_pemagent' in lookup('edb_devops.edb_postgres.supported_roles', wantlist=True and {{ pem_agent }} == true)"
       
    rescue:
    - name: delete edb cluster
      include_role:
        name: deprovision-edb-cluster    
    - name: Delete VM
      include_role:
        name: hpe-deprovision-db
      when: rollback
      vars:
        uuids: ["{{hostvars['localhost']['uuids']}}"] 
        deprovision: "vm"
    - name: SNOW_fetch_facts
      fail:
        msg: "Error occurred after configuring EDB database"   
  - block:  
    - name: Remove Python conflict package
      yum:
        name: python-psycopg2-2.5.1*
        state: absent
      when: "'primary' in {{ group_names }} and {{ barman }} == true"  
  
    - include_role:
        name: setup_barman
      when: "'primary' in {{ group_names }} and {{ barman }} == true"   
    rescue:
    - name: SNOW_fetch_facts
      fail:
        msg: "EDB deployment successful, however barman configuration failed"
