---
- name: Create a VM from a template
  hosts: localhost
  vars_files:
    - "./vars/multi_edb_provision.yml"
  vars:
  - prov_vmdetails: [ {vmname: hpedbaas-100101, uuid: 4215810b-e7b4-544f-81b5-5197a7500a0, ipaddress: 192.168.9.137}, { vmname: hpedbaas-100102, uuid: 42156f1c-89e4-4a27-a6cb-ce852be93e3e, ipaddress: 192.168.9.140} ]
  tasks:
  #- name: Validate input parameters.
  #  include_role:
  #    name: hpe-validate-params
  #  vars:
  #    type: int      

  - name: Get the hostname sequence
    tags: never
    set_fact:
      vm_list: "{{vm_list|default([])+[{'vmname': tenant_name+'-'+lookup('password','/dev/null chars=digits length=6'), 'hostname': tenant_name+'-node'+item+'.'+domain_name}]}}"
    with_sequence: start=1 end="{{nodes|int}}"
   # It generates random vm names

  - name: Get the hostname sequence
    set_fact:
      vm_list: "{{vm_list|default([])+[{'vmname': item.vmname, 'hostname':  item.vmname }]}}"
    loop: "{{ prov_vmdetails }}"
    loop_control:
      index_var: my_idx
#    loop: "{{ morpheus.instance.containers }}"

  - name: SNOW_fetch_facts
    set_fact:
      compatible_mode: "{{compatible_mode}}"
      dynatune_profile: "{{dynatune_profile}}"
      replication_mode: "{{replication_mode}}"      

  - name: VM template
    tags: never
    set_fact:
      template_name: "{{item.value}}"
    when: item.key == os_version
    with_dict: "{{ template_dict}}"

  - block:
    - name: Clone the template
      tags: never
      vmware_guest:
        hostname: "{{ vcenter_ip }}"
        username: "{{ vcenter_username }}"
        password: "{{ vcenter_password }}"
        validate_certs: False
        name: "{{ item.vmname}}"
        template: "{{ template_name }}"
        datacenter: "{{ datacenter_name }}"
        cluster: "{{ vmware_cluster_name }}"
        folder: "{{ folder_name }}"
        state: poweredon
        hardware:
          hotadd_cpu: True
          hotadd_memory: True
          hotremove_cpu: True
#          hotremove_memory: True
          num_cpus: "{{ cpu | int }}"
          memory_mb: "{{ memory | int }}"
        networks:
        - name: "{{ public_net }}"
        datastore: "{{ datastore }}"
        wait_for_ip_address: yes
      register: vm_details
      with_items: "{{vm_list}}"

    - name: SNOW_fetch_facts
      set_fact:
#        primary_ip: "{{ db_machine_ip }}"
        primary_ip: "{{ prov_vmdetails[0].ipaddress }}"
      #Gets the the ip of 1st VM and sets it as primary ip  

    - name: Getting the standby ips
      set_fact:
        standby: "{{ prov_vmdetails[1].ipaddress }}"
      when: nodes | int ==2

    - name: Getting the standby ips
      set_fact:
        standby: "{{ prov_vmdetails[1].ipaddress }},{{ prov_vmdetails[item].ipaddress }}"
      loop: "{{ range(1,nodes|int)|list }}"
      when: nodes | int >2

    - name: SNOW_fetch_facts
      set_fact:
        standby_ips: "{{standby}}"
      when: nodes | int >1

    - debug:
        var: vm_details.results
      tags: never

    - debug:
        var: vm_details.results.item.invocation.hostname
      with_items: "{{vm_details.results}}"
      tags: never

    - debug:
        var: item.invocation.name
      with_items: "{{vm_details.results}}"
      tags: never

    - name: Create nodes list
      tags: never
      set_fact:
        rac_hosts: "{{rac_hosts|default([]) + [{'node_hostname': item.item.hostname,'vmname': item.item.vmname, 'node_ip':item.instance.ipv4, 'uuid':item.instance.hw_product_uuid}]}}"
        rac_vms: "{{rac_vms|default([]) + [item.item.vmname]}}"
      with_items: "{{vm_details.results}}"

    - name: Create nodes list
      set_fact:
        rac_hosts: "{{rac_hosts|default([]) + [{'node_hostname': item.vmname,'vmname': item.vmname, 'node_ip': item.ipaddress , 'uuid': item.uuid}]}}"
        rac_vms: "{{rac_vms|default([]) + [item.vmname]}}"
      loop: "{{ prov_vmdetails }}"
      loop_control:
        index_var: my_idx

    - name: SNOW_fetch_facts
      set_fact:
        edb_nodes: "{{rac_hosts}}"
        
    - name: Getting rac hosts details
      set_fact:
        rac_nodes: "{{rac_hosts}}"        

    - set_fact:
        rac_node_uuids: "{{rac_node_uuids|default([]) + [item.uuid]}}"
      with_items: "{{rac_nodes}}"

    - name: Reference vm
      set_fact:
        reference_vm_uuid: "{{rac_nodes[0]['uuid']}}"

    - name: SNOW_fetch_facts
      set_fact:
        uuid: "{{rac_nodes[0]['uuid']}}"

    - name: SNOW_fetch_facts
      set_fact:
        vmname: "{{rac_nodes[0]['vmname']}}"

    - name: Removing entry from known_hosts if any
      known_hosts:
       name: "{{ item.node_ip }}"
       path: /root/.ssh/known_hosts
       state: absent
      with_items: "{{rac_nodes}}"
      ignore_errors: yes

    - name: Adding db vm to inventory
      add_host:
        hostname: "{{  item.node_ip }}"
        vmname: "{{item.vmname}}"
        uuid: "{{ item.uuid }}"
        groups: [ 'vmedbgroup' ]
      with_items: "{{rac_nodes}}"
      ignore_errors: yes

    - name: set uuids_val for adding disk
      set_fact:
        uuids_val: "{{ uuids_val|default([]) + [item.uuid] }}"
      with_items: "{{rac_nodes}}"

    - name: set vmname for adding disk
      set_fact:
        vmname_list: "{{ vmname_list|default([]) + [item.vmname] }}"
      with_items: "{{rac_nodes}}"

    - name: SNOW_fetch_facts
      set_fact:
        replication_type: asynchronous
      when: replication_mode=="performance"

    - name: SNOW_fetch_facts
      set_fact:
        replication_type: synchronous
      when: replication_mode=="protection"          

    - name: Adding db vm to inventory file
      add_host:
        hostname: "{{vm_list[0].vmname}}"
        ansible_host: "{{ primary_ip }}"
        private_ip: "{{ primary_ip }}"
        barman: false
        barman_server_private_ip: "{{barman_ip}}"
        barman_backup_method: postgres
        pem_agent: false
        pem_server_private_ip: "{{pem_ip}}"
        groups: [ 'primary' ]
      # It adds the inventory of primary node  

    - name: Adding db vm to inventory file
      add_host:
        hostname: "{{vm_list[item].vmname}}"
        ansible_host: "{{ rac_hosts[item].node_ip}}"
        private_ip: "{{rac_hosts[item].node_ip}}"
        upstream_node_private_ip: "{{ primary_ip }}"
        replication_type: "{{replication_type}}"
        barman: false
        barman_server_private_ip: "{{barman_ip}}"
        barman_backup_method: postgres
        pem_agent: false
        pem_server_private_ip: "{{pem_ip}}"
        groups: [ 'standby' ]
      loop: "{{ range(1,nodes|int)|list }}"  
      when: nodes | int >1 and ( replication_mode=="performance" or replication_mode=="protection")
      # It adds the inventory of standby node
      
    - name: Adding db vm to inventory file
      add_host:
        hostname: "{{vm_list[1].vmname}}"
        ansible_host: "{{rac_hosts[1].node_ip}}"
        private_ip: "{{rac_hosts[1].node_ip}}"
        upstream_node_private_ip: "{{ primary_ip }}"
        replication_type: synchronous
        barman: false
        barman_server_private_ip: "{{barman_ip}}"
        barman_backup_method: postgres
        pem_agent: false
        pem_server_private_ip: "{{pem_ip}}"
        groups: [ 'standby' ]
      when: nodes | int >1 and replication_mode=="availability" 
      # It adds the inventory of standby node   
      
    - name: Adding db vm to inventory file
      add_host:
        hostname: "{{vm_list[item].vmname}}"
        ansible_host: "{{rac_hosts[item].node_ip}}"
        private_ip: "{{rac_hosts[item].node_ip}}"        
        upstream_node_private_ip: "{{ primary_ip }}"
        replication_type: asynchronous
        barman: false
        barman_server_private_ip: "{{barman_ip}}"
        barman_backup_method: postgres
        pem_agent: false
        pem_server_private_ip: "{{pem_ip}}"
        groups: [ 'standby' ]
      loop: "{{ range(2,nodes|int)|list }}"  
      when: nodes | int >2 and replication_mode=="availability" 
      # It adds the inventory of standby node       

    - name: Adding db vm to inventory file
      add_host:
        hostname: "{{vm_list[item].vmname}}"
        ansible_host: "{{rac_hosts[item].node_ip}}"
        private_ip: "{{rac_hosts[item].node_ip}}"
        primary_private_ip: "{{ primary_ip }}"
        groups: [ 'pgpool2' ]
      loop: "{{ range(0,nodes|int)|list }}"        
      when: pgpool_enable==true and nodes | int >1
      # It adds the inventory of pgpool

    - name: Adding backup IP to inventory file
      add_host:
        hostname: "backup_server"
        ansible_host: "{{barman_ip}}"
        private_ip: "{{barman_ip}}"
        groups: [ 'barmanserver' ]
      when: barman==true
      # It adds the inventory of barman server

    - name: Adding backup IP to inventory file
      add_host:
        hostname: "pemserver_1"
        ansible_host: "{{pem_ip}}"
        private_ip: "{{pem_ip}}"
        groups: [ 'pemserver' ]
      when: pem_agent==true
      # It adds the inventory of pem server

    - name: getting rac hosts details
      set_fact:
        rac_nodes: "{{rac_hosts}}"

    - set_fact:
        rac_node_uuids: "{{rac_node_uuids|default([]) + [item.uuid]}}"
      with_items: "{{rac_nodes}}"

    - debug:
        var: rac_nodes
        
    - name: VM uuids List
      set_fact:
        vm_uuids: "{{vm_uuids|default([]) + [rac_nodes[item]['uuid']]}}"
      loop: "{{ range(0,nodes|int)|list }}"  
      
    - set_fact:
        uuids: "{{vm_uuids}}"      
      
    rescue:
    - name: Delete VM
      include_role:
        name: hpe-deprovision-db
      when: uuid is defined and rollback
      vars:
        uuids: "{{uuids}}"
        deprovision: "vm"
    - name: SNOW_fetch_facts
      fail:
        msg: "Failed while cloning VM"

- name: Gather Disk facts and Add New Disk
  hosts: localhost
  vars_files:
    - "./vars/multi_edb_provision.yml"
  vars:
    rollback: true
  tasks:
  - debug:
      msg: "{{ uuids_val }}"

  - block:
    - name: include task for adding
      include_tasks: mn_edb_extend_disk_multiple.yml
      loop: "{{ vmname_list }}"
    rescue:
    - name: Delete VM
      include_role:
        name: hpe-deprovision-db
      when: uuid is defined and rollback
      vars:
        uuids: "{{uuids}}"   
        deprovision: "vm"
    - name: SNOW_fetch_facts
      fail:
        msg: "Failed to provision disks"

- name: get disk names from host
  hosts: vmedbgroup
  vars_files:
    - "./vars/multi_edb_provision.yml"
  vars:
    rollback: true
    ssh_user: enterprisedb
  tasks:
  - block:
    - include_role:
        name: hpe-enable-passwordless-login
    - set_fact:
        new_unit_numbers: "{{ hostvars['localhost']['new_unit_numbers'] }}"
    - name: shell
      shell: ls -d /sys/block/sd*/device/scsi_device/* |awk -F '[:/]' '{print "/dev/"$4,$9}' | grep "{{ item }}" | cut -f1 -d " "
      register: disk_names
      with_items:
      - "{{ new_unit_numbers }}"
    - set_fact:
        db_disks: "{{db_disks |default([]) + [item.stdout] }}"
        data_disks: "{{data_disks|default([]) + [{ 'device': item.stdout, 'pvname': item.stdout }]}}"
      when: item.stdout
      with_items:
      - "{{disk_names.results }}"

    rescue:
    - name: Delete VM
      include_role:
        name: hpe-deprovision-db
      when: uuid is defined and rollback
      vars:
        uuids: ["{{hostvars['localhost']['uuids']}}"]   
        deprovision: "vm"
    - name: SNOW_fetch_facts
      fail:
        msg: "Error occurred while gathering disk facts"
  
- name: Configure fs,vgs and lvs
  hosts: vmedbgroup
  vars_files:
    - "./vars/multi_edb_provision.yml"
  vars:
    rollback: true
    configure_host_disks: true
  tasks:
  - block:
    - set_fact:
        mnt_pt: "/pg/edbvol1"
      when: pg_type == 'EPAS'
      
    - set_fact:
        mnt_pt: "/pg/pgvol1"
      when: pg_type == 'PG'
      
    - include_role:
        name: hpe-edb-partition
    rescue:
    - name: Delete VM
      include_role:
        name: hpe-deprovision-db
      when: rollback
      vars:
        uuids: ["{{hostvars['localhost']['uuids']}}"] 
        deprovision: "vm"
    - name: SNOW_fetch_facts
      fail:
        msg: "Failed to add database disk"

- name: Extend vgs and lvs
  hosts: vmedbgroup
  vars_files:
    - "./vars/multi_edb_provision.yml"
  roles:
  - role: hpe-oradb-vm-add-storage

- name: Get New DBSize
  hosts: vmedbgroup
  vars_files:
    - "./vars/multi_edb_provision.yml"
  tasks:
  - name: run df command 
    shell: df -h | grep "{{ vg_name }}" | tail -1 | awk '{print $2}'
    register: total_lvm_size_gb
    
  - name: SNOW_fetch_facts
    set_fact:
      extended_disk_size: "{{ total_lvm_size_gb.stdout }}"

#- name: Update DNS, Hostname
#  hosts: vmedbgroup
#  become: yes
#  vars:
#    rollback: true
#    oracle_sid: "{{ database_name }}"
#  tasks:
#  - block:
#    - include_role:
#        name: hpe-configure-hostname-dns
#    rescue:
#    - name: Delete VM
#      include_role:
#        name: hpe-deprovision-db
#      when: rollback
#      vars:
#        uuids: ["{{hostvars['localhost']['uuids']}}"]       
#        deprovision: "vm"
#    - name: SNOW_fetch_facts
#      fail:
#        msg: "Error occurred while configuring database"

- name: EDB deployment
  hosts: primary,standby
  vars_files:
    - "./vars/multi_edb_provision.yml"
  vars:
    edb_policy_file: "data/edb_policy.json"
    jsonInput: "{{ lookup('file', edb_policy_file) | from_json }}"
    policyName: "{{ backup_policy }}"
    edb_policy_full: "{{ jsonInput[policyName]['policy_full'] }}"
    frequency_full: "{{ jsonInput[policyName]['frequency_full'] }}"
    edb_retention_policy: "{{ jsonInput[policyName]['retention'] }}"
    efm_version: 4.0
    efm_parameters:
      - name: ping.server.ip
        value: "{{dns_server}}"
  gather_facts: yes
  become: yes
  any_errors_fatal: True
  max_fail_percentage: 0

  pre_tasks:
  - name: Initialize the user defined variables
    set_fact:
      pg_version: "{{ edb_version }}"
      pg_type: "EPAS"
      pg_port: "{{ port_number }}"
      disable_logging: no         
    
  - set_fact:
      pg_superuser: enterprisedb
      pg_database: "{{compatible_mode}}"
      pg_efm_database: "{{compatible_mode}}"
      pg_databases:
        - name: "{{ db_name }}"
          owner: enterprisedb
          encoding: UTF-8
    when: pg_type == 'EPAS'
     
  - set_fact:
      pg_superuser: postgres
      pg_database: postgres
      pg_efm_database: postgres
      pg_databases:
        - name: "{{ db_name }}"
          owner: postgres
          encoding: UTF-8
      pg_service: 'postgresql-{{ edb_version }}-{{cluster_name}}-{{port_number}}'    
    when: pg_type == 'PG'  
    
  - set_fact:
      pg_initdb_options: "--auth=peer --auth-host=scram-sha-256 --encoding=UTF-8 --locale=en_US.UTF-8 --data-checksums --no-redwood-compat"
      pg_database: "postgres"
      pg_efm_database: "postgres"
    when: compatible_mode=="postgres"

  - set_fact:
      pg_instance_name: "{{ cluster_name }}-{{ pg_port }}"

  - set_fact:
      pg_data: "/pg/edbvol1/edb/as{{ pg_version }}/{{ pg_instance_name }}/data"
      pg_default_data: "/pg/edbvol1/edb/as{{ pg_version }}/{{ pg_instance_name }}/data"
    when: pg_type == 'EPAS'  
    
  - set_fact: 
      pg_data: "/pg/pgvol1/pgsql/{{ pg_version }}/{{ pg_instance_name }}/data"
      pg_default_data: "/pg/pgvol1/pgsql/{{pg_version}}/{{ pg_instance_name }}/data"
    when: pg_type == 'PG'   
      
  - name: Setting up a edb, epel and rhel repo
    get_url:
     url: "{{item}}"
     dest: /etc/yum.repos.d
     mode: '0440'
     validate_certs: no  
    loop:
     - "{{edb_repo}}"
     - "{{epel_repo}}"
     - "{{rhel_repo}}"  
    become: yes 
  tasks:
  - block:     
    - include_role:
        name: install_dbserver
      when: "'install_dbserver' in lookup('edb_devops.edb_postgres.supported_roles', wantlist=True)"
    
    - include_role:
        name: init_dbserver
      when: "'init_dbserver' in lookup('edb_devops.edb_postgres.supported_roles', wantlist=True)"
      
    - include_role:
        name: manage_dbserver
      when: "'primary' in {{ group_names }}"          
    rescue:
    - name: Delete VM
      include_role:
        name: hpe-deprovision-db        
      when: rollback
      vars:
        uuids: ["{{hostvars['localhost']['uuids']}}"] 
        deprovision: "vm"
    - name: SNOW_fetch_facts
      fail:
        msg: "Error occurred while configuring EDB database"      

- name: Snow fetch facts details of primary
  hosts: primary
  vars_files:
    - "./vars/multi_edb_provision.yml"
  tasks:
  - block:
    - name: Get EPAS version
      shell: psql --version|awk ' {print $3}'
      register: db_version
    - debug:
       var: db_version.stdout
    - name: SNOW_fetch_facts
      set_fact:
        db_name: "{{ db_name }}"
        cluster_name: "{{pg_instance_name}}"
        listen_port: "{{ port_number }}"
        db_version: "{{ db_version.stdout }}"
        pg_data: "{{pg_data}}"
        db_size: "{{(db_size|int)*(number_of_luns|int)}}"
        nodes: "{{nodes}}"

- name: Pgpool2 vip generation
  hosts: pgpool2
  vars_files:
    - "./vars/multi_edb_provision.yml"
  vars: 
    oracle_cluster_name: "{{pg_instance_name}}"
  tasks:
  - block:  
    - include_role:
        name: hpe-get-ips-from-pool
      vars:
        total_ips: "1"
        oracle_cluster_name: "{{pg_instance_name}}"
      when: pgpool_enable==true and nodes | int >1
      
    - set_fact:
        pgpool_vip: "{{usable_ips[0]}}"
      when: pgpool_enable==true and nodes | int >1
      
    - debug:
        var: cluster_name 
    
    rescue:
    - name: Delete VM
      include_role:
        name: hpe-deprovision-db
      when: rollback  
      vars:
        uuids: ["{{hostvars['localhost']['uuids']}}"] 
        deprovision: "vm"        
    - name: SNOW_fetch_facts
      fail:
        msg: "Failed, Could not get vip for pgpool2."    
  
- name: Enable Barman backup deployment
  hosts: primary,barmanserver,standby,pemserver,pgpool2
  vars_files:
    - "./vars/multi_edb_provision.yml"
  gather_facts: yes
  become: yes
  vars:
   barman: false
   pem_agent: false
   backup_method: postgres
   use_hostname: true
   edb_policy_file: "data/edb_policy.json"
   jsonInput: "{{ lookup('file', edb_policy_file) | from_json }}"
   policyName: "{{ backup_policy }}"
   edb_policy_full: "{{ jsonInput[policyName]['policy_full'] }}"
   frequency_full: "{{ jsonInput[policyName]['frequency_full'] }}"
   edb_retention_policy: "{{ jsonInput[policyName]['retention'] }}"
   efm_version: 4.0
   efm_parameters:
     - name: ping.server.ip
       value: "{{dns_server}}"
   pgpool2_load_balancing: true
   pgpool2_watchdog: true
   pgpool2_vip_dev: "{{pgpool_dev}}"
   pgpool2_port: 5433
   total_ips: "1"
   pgpool2_vip: "{{pgpool_vip}}"
  pre_tasks:
  - name: Initialize the user defined variables
    set_fact:
      pg_version: "{{ edb_version }}"
      pg_type: "EPAS"
      pg_port: "{{ port_number }}"      
      disable_logging: false
      any_errors_fatal: True
      max_fail_percentage: 0      
    become: yes   
  
  - set_fact:
      pg_initdb_options: "--auth=peer --auth-host=scram-sha-256 --encoding=UTF-8 --locale=en_US.UTF-8 --data-checksums --no-redwood-compat"
      pg_database: "postgres"
      pg_efm_database: "postgres"
    when: compatible_mode=="postgres"

  - set_fact:
      pg_instance_name: "{{ cluster_name }}-{{ pg_port }}"
      
  - set_fact:
      pg_superuser: enterprisedb
      pg_database: "{{compatible_mode}}"
      pg_efm_database: "{{compatible_mode}}"
      pg_databases:
        - name: "{{ db_name }}"
          owner: enterprisedb
          encoding: UTF-8
    when: pg_type == 'EPAS'
     
  - set_fact:
      pg_superuser: postgres
      pg_database: postgres
      pg_efm_database: postgres
      pg_databases:
        - name: "{{ db_name }}"
          owner: postgres
          encoding: UTF-8
      pg_service: 'postgresql-{{ edb_version }}-{{cluster_name}}-{{port_number}}'    
    when: pg_type == 'PG'
   
  - set_fact:
      pg_data: "/pg/edbvol1/edb/as{{ pg_version }}/{{ pg_instance_name }}/data"
      pg_default_data: "/pg/edbvol1/edb/as{{ pg_version }}/{{ pg_instance_name }}/data"
    when: pg_type == 'EPAS'  
    
  - set_fact: 
      pg_data: "/pg/pgvol1/pgsql/{{ pg_version }}/{{ pg_instance_name }}/data"
      pg_default_data: "/pg/pgvol1/pgsql/{{pg_version}}/{{ pg_instance_name }}/data"
    when: pg_type == 'PG' 
    
    become: yes 
  tasks: 
  - block:  
    - include_role:
        name: setup_replication
      when: "'setup_replication' in lookup('edb_devops.edb_postgres.supported_roles', wantlist=True) and ({{nodes | int}} >1)"
    
    - include_role:
        name: setup_efm
      when: "'setup_efm' in lookup('edb_devops.edb_postgres.supported_roles', wantlist=True) and ({{nodes | int}} >1)"
      
    - include_role:
        name: setup_pgpool2
      when: "'setup_pgpool2' in lookup('edb_devops.edb_postgres.supported_roles', wantlist=True) and ({{nodes | int}} >1) and {{ pgpool_enable }} == true"
      
    - include_role:
        name: setup_pemagent
      when: "'setup_pemagent' in lookup('edb_devops.edb_postgres.supported_roles', wantlist=True and {{ pem_agent }} == true)"
       
    rescue:
    - name: delete edb cluster
      include_role:
        name: deprovision-edb-cluster    
    - name: Delete VM
      include_role:
        name: hpe-deprovision-db
      when: rollback
      vars:
        uuids: ["{{hostvars['localhost']['uuids']}}"] 
        deprovision: "vm"
    - name: SNOW_fetch_facts
      fail:
        msg: "Error occurred after configuring EDB database"   
  - block:  
    - name: Remove Python conflict package
      yum:
        name: python-psycopg2-2.5.1*
        state: absent
      when: "'primary' in {{ group_names }} and {{ barman }} == true"  
  
    - include_role:
        name: setup_barman
      when: "'primary' in {{ group_names }} and {{ barman }} == true"   
    rescue:
    - name: SNOW_fetch_facts
      fail:
        msg: "EDB deployment successful, however barman configuration failed"
